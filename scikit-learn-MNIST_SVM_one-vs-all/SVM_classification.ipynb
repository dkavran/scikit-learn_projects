{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000],y[60000:]\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificators = [None] * 10\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "kernels = ['linear']\n",
    "probability = [True]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, train_size=6000, test_size=1000, random_state=42)\n",
    "#smaller train and test sets to speed up the process - consequently smaller precision and recall\n",
    "for index in range(10):\n",
    "    y_train_tmp = (y_train == index)\n",
    "    svc = SVC()\n",
    "    \n",
    "    parameters = {'C': Cs,'kernel':kernels, 'probability':probability}\n",
    "    \n",
    "    grid_search = GridSearchCV(svc, parameters, n_jobs=-1, cv=3)\n",
    "    grid_search.fit(X_train, y_train_tmp)\n",
    "\n",
    "    svc = grid_search.best_estimator_\n",
    "    classificators[index] = svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = [None] * 10\n",
    "for index, classificator in enumerate(classificators):\n",
    "    probabilities[index] = classificator.predict_proba(X_test)[:,1]\n",
    "probabilities = np.asarray(probabilities)\n",
    "predictions = probabilities.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95        97\n",
      "          1       0.97      0.93      0.95       127\n",
      "          2       0.82      0.84      0.83        93\n",
      "          3       0.78      0.81      0.79       112\n",
      "          4       0.83      0.85      0.84        97\n",
      "          5       0.74      0.81      0.77        83\n",
      "          6       0.91      0.89      0.90        97\n",
      "          7       0.92      0.90      0.91       119\n",
      "          8       0.70      0.73      0.72        78\n",
      "          9       0.75      0.74      0.75        97\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1000\n",
      " \n",
      " [[ 88   0   0   0   0   0   0   1   0   0]\n",
      " [  0 118   2   0   1   0   0   0   0   1]\n",
      " [  1   4  78   3   2   1   1   0   5   0]\n",
      " [  0   1   4  91   0  10   0   0   7   4]\n",
      " [  0   0   2   0  82   0   5   1   1   8]\n",
      " [  0   1   2   7   1  67   2   0   4   7]\n",
      " [  4   0   1   0   1   1  86   0   1   0]\n",
      " [  0   1   0   1   1   1   0 107   1   4]\n",
      " [  3   2   3   7   1   3   3   1  57   1]\n",
      " [  1   0   1   3   8   0   0   9   2  72]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test),\"\\n\",confusion_matrix(y_test,predictions)) #around 0.86 both precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
